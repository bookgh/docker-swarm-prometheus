version: '3.3'
services:
  dockerd_exporter:
    image: harbor.iibu.com/base/dockerd-exporter:v0.0.1
    volumes:
      - /etc/localtime:/etc/localtime:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9323/metrics"]
      interval: 5s
      timeout: 1s
      retries: 3
    networks:
      - monitor
    deploy:
      mode: global
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  # monitor host
  node_exporter:
    image: harbor.iibu.com/base/node-exporter:v0.16.0
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
      - /etc/hostname:/etc/nodename:ro
      - /etc/localtime:/etc/localtime:ro
    environment:
      - NODE_ID={{.Node.ID}}
    command:
      - '--path.sysfs=/host/sys'
      - '--path.procfs=/host/proc'
      - '--collector.textfile.directory=/etc/node-exporter/'
      - '--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)'
      - '--no-collector.ipvs'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9100/metrics"]
      interval: 5s
      timeout: 1s
      retries: 3
    networks:
      - monitor
    deploy:
      mode: global
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  # monitor docker container
  cadvisor_exporter:
    image: harbor.iibu.com/base/cadvisor:v0.31.0
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /dev:/dev/:ro
      - /etc/hostname:/etc/nodename:ro
      - /etc/localtime:/etc/localtime:ro
    command: -logtostderr -docker_only
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/metrics"]
      interval: 5s
      timeout: 1s
      retries: 3
    networks:
      - monitor
    deploy:
      mode: global
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  redis_exporter:
    image: harbor.iibu.com/base/redis_exporter:v0.22.1
    volumes:
      - /etc/localtime:/etc/localtime:ro
    environment:
      - REDIS_ADDR=192.168.50.21:6981,192.168.50.24:6981,192.168.50.25:6981,192.168.50.68:6981,192.168.50.171:6981,192.168.50.192:6981
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9121/metrics"]
      interval: 5s
      timeout: 1s
      retries: 3
    networks:
      - monitor
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          # - node.labels.app == redis
          - node.role == manager
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  mysqld_exporter0:
    image: harbor.iibu.com/base/mysqld_exporter:v0.11.0
    volumes:
      - /etc/localtime:/etc/localtime:ro
    environment:
      - DATA_SOURCE_NAME=exporter:HfOu23LCymB8np2Vt4qf@(192.168.50.54:3306)/
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9104/metrics"]
      interval: 5s
      timeout: 1s
      retries: 3
    ports:
      - "29104:9104"
    networks:
      - monitor
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          # - node.labels.app == marriadb
          - node.role == manager
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  mysqld_exporter1:
    image: harbor.iibu.com/base/mysqld_exporter:v0.11.0
    volumes:
      - /etc/localtime:/etc/localtime:ro
    environment:
      - DATA_SOURCE_NAME=exporter:HfOu23LCymB8np2Vt4qf@(192.168.50.149:3306)/
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9104/metrics"]
      interval: 5s
      timeout: 1s
      retries: 3
    ports:
      - "29105:9104"
    networks:
      - monitor
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          # - node.labels.app == marriadb
          - node.role == manager
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  mysqld_exporter2:
    image: harbor.iibu.com/base/mysqld_exporter:v0.11.0
    volumes:
      - /etc/localtime:/etc/localtime:ro
    environment:
      - DATA_SOURCE_NAME=exporter:HfOu23LCymB8np2Vt4qf@(192.168.50.62:3306)/
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9104/metrics"]
      interval: 5s
      timeout: 1s
      retries: 3
    ports:
      - "29106:9104"
    networks:
      - monitor
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          # - node.labels.app == marriadb
          - node.role == manager
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  mysqld_exporter3:
    image: harbor.iibu.com/base/mysqld_exporter:v0.11.0
    volumes:
      - /etc/localtime:/etc/localtime:ro
    environment:
      - DATA_SOURCE_NAME=exporter:HfOu23LCymB8np2Vt4qf@(192.168.50.174:3306)/
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9104/metrics"]
      interval: 5s
      timeout: 1s
      retries: 3
    ports:
      - "29107:9104"
    networks:
      - monitor
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          # - node.labels.app == marriadb
          - node.role == manager
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  rabbitmq_exporter:
    image: harbor.iibu.com/base/rabbitmq-exporter:v1.0.0
    volumes:
      - /etc/localtime:/etc/localtime:ro
    environment:
      - RABBIT_USER=user
      - RABBIT_PASSWORD=password
      - RABBIT_URL=http://192.168.210.53:15672
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9419/metrics"]
      interval: 5s
      timeout: 1s
      retries: 3
    ports:
      - "19419:9419"
    networks:
      - monitor
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  # push short-lived jobs
  pushgateway:
    image: harbor.iibu.com/base/pushgateway:v0.6.0
    volumes:
      - /etc/localtime:/etc/localtime:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/metrics"]
      interval: 5s
      timeout: 1s
      retries: 3
    networks:
      - monitor
    # swarm
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  # datasource
  prometheus:
    image: harbor.iibu.com/base/prometheus:v2.4.3
    user: root
    volumes:
      - /monitor/prometheus/data:/prometheus
      - /monitor/prometheus/config:/etc/prometheus
      - /etc/localtime:/etc/localtime:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    configs:
      - source: prometheus_config
        target: /prometheus.yml
      - source: app_rules
        target: /etc/prometheus/app.rules.yml
      - source: containers_rules
        target: /etc/prometheus/containers.rules.yml
      - source: kibana_rules
        target: /etc/prometheus/kibana.rules.yml
      - source: marriadb_rules
        target: /etc/prometheus/marriadb.rules.yml
      - source: node_rules
        target: /etc/prometheus/node.rules.yml
      - source: prometheus_rules
        target: /etc/prometheus/prometheus.rules.yml
      - source: rabbitmq_rules
        target: /etc/prometheus/rabbitmq.rules.yml
      - source: redis_rules
        target: /etc/prometheus/redis.rules.yml
      - source: svn_rules
        target: /etc/prometheus/svn.rules.yml
    environment:
      - exporters=node_exporter cadvisor_exporter dockerd_exporter redis_exporter pushgateway
      - stack=monitor
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention=24h'
      - '--web.enable-lifecycle'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/metrics"]
      interval: 60s
      timeout: 10s
      retries: 3
    networks:
      - monitor
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 2048M
        reservations:
          memory: 128M

  # alert
  alertmanager:
    image: harbor.iibu.com/base/alertmanager:v0.15.2
    volumes: 
      - /etc/localtime:/etc/localtime:ro
    configs:
      - source: alert_config
        target: /alertmanager.yml
      - source: alert_all_tmpl
        target: /etc/alertmanager/template/all.tmpl
    command:
      - '--config.file=/etc/alertmanager/config/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--data.retention=9999h'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9093/"]
      interval: 5s
      timeout: 1s
      retries: 3
    networks:
      - monitor
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  unsee:
    image: harbor.iibu.com/base/unsee:v0.9.2
    environment:
      - "ALERTMANAGER_URIS=default:http://alertmanager:9093"
      - "PORT=9080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9080"]
      interval: 5s
      timeout: 1s
      retries: 3
    networks:
      - monitor
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  # dashboard
  grafana:
    image: harbor.iibu.com/base/grafana:v5.3.1
    volumes:
      - /monitor/grafana/data:/grafana/data
      - /etc/localtime:/etc/localtime:ro
    environment:
      - GF_SECURITY_ADMIN_USER=${ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 5s
      timeout: 1s
      retries: 3
    networks:
      - monitor
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  # web authorization
  caddy:
    image: harbor.iibu.com/base/caddy:v0.11.0
    ports:
      # grafana
      - "23000:3000"
      # prometheus
      - "29090:9090"
      # alertmanager
      - "29093:9093"
      # nodeexporter
      - "29100:9100"
      # cadvisor
      - "28080:8080"
      # unsee
      - "29080:9080"
      # pushgateway
      - "29091:9091"
      # dockerd-exporter
      - "29323:9323"
      # redis_exporter
      - "29121:9121"
    volumes:
      - /etc/localtime:/etc/localtime:ro
    configs:
      - source: caddy_config
        target: /etc/caddy/Caddyfile
    environment:
      - ADMIN_USER=${ADMIN_USER:-admin}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin}
    networks:
      - monitor
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 5s
      timeout: 1s
      retries: 5

networks:
  monitor:
    driver: overlay
    attachable: true

configs:
  caddy_config:
    file: ./caddy/config/Caddyfile
  alert_config:
    file: ./alertmanager/config/alertmanager.yml
  alert_all_tmpl:
    file: ./alertmanager/template/all.tmpl
  prometheus_config:
    file: ./prometheus/config/prometheus.yml
  app_rules:
    file: ./prometheus/rules/app.rules.yml
  containers_rules:
    file: ./prometheus/rules/containers.rules.yml
  kibana_rules:
    file: ./prometheus/rules/kibana.rules.yml
  marriadb_rules:
    file: ./prometheus/rules/marriadb.rules.yml
  node_rules:
    file: ./prometheus/rules/node.rules.yml
  prometheus_rules:
    file: ./prometheus/rules/prometheus.rules.yml
  rabbitmq_rules:
    file: ./prometheus/rules/rabbitmq.rules.yml
  redis_rules:
    file: ./prometheus/rules/redis.rules.yml
  svn_rules:
    file: ./prometheus/rules/svn.rules.yml
